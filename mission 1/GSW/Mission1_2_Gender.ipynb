{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pw4UjG1Qge6",
        "outputId": "04bb96c4-db94-4597-f640-6a774c71f8d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "oBye6ggWXBjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "import os"
      ],
      "metadata": {
        "id": "nn2EbmrNSmce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2."
      ],
      "metadata": {
        "id": "kd5yl0CHXCT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
        "\n",
        "# Train 데이터셋 경로 (processed_images와 sorted_training_images)\n",
        "train_dir_1 = '/content/drive/MyDrive/mission_data/gender_processed_images'\n",
        "train_dir_2 = '/content/drive/MyDrive/mission_data/gender_training_images'\n",
        "\n",
        "# 이미지 데이터 경로 설정\n",
        "input_dir = '/content/drive/MyDrive/mission_data/gender_validation_images'\n",
        "\n",
        "# 이미지 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ResNet은 224x224 입력 크기를 기대함\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet 사전 학습된 모델 정규화\n",
        "])\n",
        "\n",
        "# 각 경로의 데이터셋 불러오기\n",
        "train_dataset_1 = datasets.ImageFolder(root=train_dir_1, transform=transform)\n",
        "train_dataset_2 = datasets.ImageFolder(root=train_dir_2, transform=transform)\n",
        "\n",
        "# 두 개의 데이터셋을 합침\n",
        "train_dataset = ConcatDataset([train_dataset_1, train_dataset_2])\n",
        "\n",
        "# 전체 validation/test 데이터셋\n",
        "dataset = datasets.ImageFolder(root=input_dir, transform=transform)\n",
        "\n",
        "# 전체 이미지 및 라벨 추출\n",
        "image_indices = np.arange(len(dataset))  # 이미지 인덱스\n",
        "labels = np.array([dataset.targets[i] for i in image_indices])  # 각 이미지의 라벨\n",
        "\n",
        "# StratifiedShuffleSplit 사용 (train 50%, validation 50%)\n",
        "splitter = StratifiedShuffleSplit(n_splits=1, test_size=476, random_state=42)\n",
        "\n",
        "val_indices, test_indices = next(splitter.split(image_indices, labels))\n",
        "\n",
        "# Subset을 사용하여 train/validation 데이터셋 분리\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "test_dataset = Subset(dataset, test_indices)\n",
        "\n",
        "# DataLoader 설정\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train size: {len(train_loader.dataset)}, Val size: {len(val_loader.dataset)}, Test size: {len(test_loader.dataset)}\")"
      ],
      "metadata": {
        "id": "9RQVvJN-Tc_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4f00fe-0552-4e15-f608-3d0e7512b382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 8140, Val size: 475, Test size: 476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3."
      ],
      "metadata": {
        "id": "boLpndoUXDkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "def count_class_images_in_concat(dataset, dataset_name):\n",
        "    class_counts = Counter()\n",
        "\n",
        "    # ConcatDataset 안의 각 데이터셋을 순회\n",
        "    for sub_dataset in dataset.datasets:\n",
        "        if isinstance(sub_dataset, torch.utils.data.Subset):\n",
        "            # Subset인 경우 원본 데이터셋의 targets 사용\n",
        "            labels = [sub_dataset.dataset.targets[i] for i in sub_dataset.indices]\n",
        "        else:\n",
        "            # Subset이 아닌 경우 직접 targets 사용\n",
        "            labels = sub_dataset.targets\n",
        "\n",
        "        # 각 클래스의 이미지 수를 계산하고 합산\n",
        "        class_counts.update(labels)\n",
        "\n",
        "    # DataFrame으로 변환\n",
        "    class_distribution = pd.DataFrame(class_counts.items(), columns=['Class', 'Number of Images'])\n",
        "    class_distribution['Dataset'] = dataset_name\n",
        "\n",
        "    return class_distribution\n",
        "\n",
        "def count_class_images_in_dataset(dataset, dataset_name):\n",
        "    # Subset인 경우와 아닌 경우를 처리\n",
        "    if isinstance(dataset, torch.utils.data.Subset):\n",
        "        labels = [dataset.dataset.targets[i] for i in dataset.indices]\n",
        "    else:\n",
        "        labels = dataset.targets\n",
        "\n",
        "    # 각 클래스의 이미지 수를 계산\n",
        "    class_counts = Counter(labels)\n",
        "\n",
        "    # DataFrame으로 변환\n",
        "    class_distribution = pd.DataFrame(class_counts.items(), columns=['Class', 'Number of Images'])\n",
        "    class_distribution['Dataset'] = dataset_name\n",
        "\n",
        "    return class_distribution\n",
        "\n",
        "# Train 데이터셋이 ConcatDataset인 경우 처리\n",
        "if isinstance(train_dataset, torch.utils.data.ConcatDataset):\n",
        "    train_distribution = count_class_images_in_concat(train_dataset, \"Train\")\n",
        "else:\n",
        "    train_distribution = count_class_images_in_dataset(train_dataset, \"Train\")\n",
        "\n",
        "# Validation과 Test 데이터셋의 클래스 수 세기\n",
        "val_distribution = count_class_images_in_dataset(val_dataset, \"Validation\")\n",
        "test_distribution = count_class_images_in_dataset(test_dataset, \"Test\")\n",
        "\n",
        "# 세 DataFrame 합치기\n",
        "combined_distribution = pd.concat([train_distribution, val_distribution, test_distribution], ignore_index=True)\n",
        "\n",
        "# pivot을 사용하여 옆으로 나열\n",
        "pivot_distribution = combined_distribution.pivot(index='Class', columns='Dataset', values='Number of Images').fillna(0)\n",
        "\n",
        "# 원하는 컬럼 순서로 재배열\n",
        "pivot_distribution = pivot_distribution[['Train', 'Validation', 'Test']]\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Combined Class Distribution (Pivoted):\")\n",
        "pivot_distribution\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "dymUGut91P38",
        "outputId": "921fc725-f687-47f4-e0e3-7b5f3376310b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Class Distribution (Pivoted):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset  Train  Validation  Test\n",
              "Class                           \n",
              "0         4496         262   263\n",
              "1         3644         213   213"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f2189a4-5657-4028-becd-ced012dbfe58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Dataset</th>\n",
              "      <th>Train</th>\n",
              "      <th>Validation</th>\n",
              "      <th>Test</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4496</td>\n",
              "      <td>262</td>\n",
              "      <td>263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3644</td>\n",
              "      <td>213</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f2189a4-5657-4028-becd-ced012dbfe58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f2189a4-5657-4028-becd-ced012dbfe58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f2189a4-5657-4028-becd-ced012dbfe58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e4af62ab-f60a-4f19-b32b-f7b123102cd4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4af62ab-f60a-4f19-b32b-f7b123102cd4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e4af62ab-f60a-4f19-b32b-f7b123102cd4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_68dd1410-efdc-410a-975f-4b7cd84d5b6a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pivot_distribution')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_68dd1410-efdc-410a-975f-4b7cd84d5b6a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pivot_distribution');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pivot_distribution",
              "summary": "{\n  \"name\": \"pivot_distribution\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 602,\n        \"min\": 3644,\n        \"max\": 4496,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3644,\n          4496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34,\n        \"min\": 213,\n        \"max\": 262,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          213,\n          262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35,\n        \"min\": 213,\n        \"max\": 263,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          213,\n          263\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4."
      ],
      "metadata": {
        "id": "4Si6n926XakD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 30\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Device 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ResNet-18 모델 정의\n",
        "model = models.resnet18(weights=None)  # pretrained=False로 설정\n",
        "num_features = model.fc.in_features  # 마지막 FC 레이어의 입력 크기\n",
        "model.fc = nn.Linear(num_features, 2)  # 출력 클래스 수에 맞게 수정\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss 및 Optimizer 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Learning Rate Scheduler 설정\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "metadata": {
        "id": "ZW1hxgo0_yja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 체크포인트 저장 함수\n",
        "def save_checkpoint(state, filename=\"/content/drive/MyDrive/GSW/checkpoint.pth\", weights_only=False):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "# 체크포인트 로드 함수\n",
        "def load_checkpoint(filename=\"/content/drive/MyDrive/GSW/checkpoint.pth\", weights_only=False):\n",
        "    checkpoint = torch.load(filename)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    best_accuracy = checkpoint['best_accuracy']\n",
        "    return epoch, best_accuracy"
      ],
      "metadata": {
        "id": "a1cDnITAoqyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 및 검증 함수\n",
        "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, start_epoch=0, best_accuracy=0.0):\n",
        "    history = {'train_loss': [], 'train_accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass 및 최적화\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Accuracy 계산\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        accuracy = correct_predictions / total_samples\n",
        "        history['train_loss'].append(avg_loss)\n",
        "        history['train_accuracy'].append(accuracy)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_correct_predictions = 0\n",
        "        val_total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_running_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total_samples += labels.size(0)\n",
        "                val_correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "        avg_val_loss = val_running_loss / len(val_loader)\n",
        "        val_accuracy = val_correct_predictions / val_total_samples\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # 가장 높은 정확도를 가진 모델 저장\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        # 체크포인트 저장\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,  # 현재 에폭 저장\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_accuracy': best_accuracy\n",
        "\n",
        "        })\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "2tdUgH3Lorbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 만약 기존 체크포인트가 있다면 로드\n",
        "try:\n",
        "    start_epoch, best_accuracy = load_checkpoint()\n",
        "    print(f\"Checkpoint loaded. Resuming from epoch {start_epoch} with best accuracy {best_accuracy:.4f}.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"No checkpoint found, starting from scratch.\")\n",
        "    start_epoch, best_accuracy = 0, 0.0\n",
        "\n",
        "# 학습 재개\n",
        "history = train_and_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, start_epoch, best_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n59D1Vo-os0o",
        "outputId": "6f309af0-7a31-46d2-e21b-85d785df0422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-e49157ed0381>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded. Resuming from epoch 6 with best accuracy 0.6695.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 7/30: 100%|██████████| 128/128 [2:25:49<00:00, 68.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/30], Train Loss: 0.5927, Train Accuracy: 0.6826\n",
            "Validation Loss: 0.6272, Validation Accuracy: 0.6316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 8/30: 100%|██████████| 128/128 [52:16<00:00, 24.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/30], Train Loss: 0.5617, Train Accuracy: 0.7136\n",
            "Validation Loss: 0.6523, Validation Accuracy: 0.6379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 9/30: 100%|██████████| 128/128 [52:11<00:00, 24.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/30], Train Loss: 0.5211, Train Accuracy: 0.7479\n",
            "Validation Loss: 0.6514, Validation Accuracy: 0.6611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 10/30: 100%|██████████| 128/128 [52:29<00:00, 24.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/30], Train Loss: 0.4952, Train Accuracy: 0.7619\n",
            "Validation Loss: 0.4877, Validation Accuracy: 0.7705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 11/30: 100%|██████████| 128/128 [53:00<00:00, 24.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/30], Train Loss: 0.3834, Train Accuracy: 0.8240\n",
            "Validation Loss: 0.4609, Validation Accuracy: 0.7895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 12/30: 100%|██████████| 128/128 [53:05<00:00, 24.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/30], Train Loss: 0.3123, Train Accuracy: 0.8655\n",
            "Validation Loss: 0.4639, Validation Accuracy: 0.8400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 13/30: 100%|██████████| 128/128 [52:38<00:00, 24.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/30], Train Loss: 0.2379, Train Accuracy: 0.9010\n",
            "Validation Loss: 0.6092, Validation Accuracy: 0.7726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 14/30: 100%|██████████| 128/128 [52:32<00:00, 24.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/30], Train Loss: 0.1562, Train Accuracy: 0.9398\n",
            "Validation Loss: 0.5489, Validation Accuracy: 0.8274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 15/30: 100%|██████████| 128/128 [52:47<00:00, 24.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/30], Train Loss: 0.1206, Train Accuracy: 0.9529\n",
            "Validation Loss: 0.5356, Validation Accuracy: 0.8547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 16/30: 100%|██████████| 128/128 [52:36<00:00, 24.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/30], Train Loss: 0.0836, Train Accuracy: 0.9699\n",
            "Validation Loss: 0.3838, Validation Accuracy: 0.8674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 17/30: 100%|██████████| 128/128 [52:32<00:00, 24.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/30], Train Loss: 0.0431, Train Accuracy: 0.9845\n",
            "Validation Loss: 0.4683, Validation Accuracy: 0.8758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 18/30: 100%|██████████| 128/128 [52:46<00:00, 24.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/30], Train Loss: 0.0505, Train Accuracy: 0.9834\n",
            "Validation Loss: 0.5610, Validation Accuracy: 0.8632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 19/30: 100%|██████████| 128/128 [52:41<00:00, 24.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/30], Train Loss: 0.0366, Train Accuracy: 0.9876\n",
            "Validation Loss: 0.4967, Validation Accuracy: 0.8926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 20/30: 100%|██████████| 128/128 [52:30<00:00, 24.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/30], Train Loss: 0.0345, Train Accuracy: 0.9873\n",
            "Validation Loss: 0.5469, Validation Accuracy: 0.8884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 21/30: 100%|██████████| 128/128 [52:25<00:00, 24.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/30], Train Loss: 0.0110, Train Accuracy: 0.9972\n",
            "Validation Loss: 0.4562, Validation Accuracy: 0.8926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 22/30: 100%|██████████| 128/128 [52:42<00:00, 24.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/30], Train Loss: 0.0062, Train Accuracy: 0.9980\n",
            "Validation Loss: 0.4418, Validation Accuracy: 0.8989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 23/30: 100%|██████████| 128/128 [52:56<00:00, 24.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/30], Train Loss: 0.0023, Train Accuracy: 0.9998\n",
            "Validation Loss: 0.4733, Validation Accuracy: 0.8926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 24/30: 100%|██████████| 128/128 [52:31<00:00, 24.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/30], Train Loss: 0.0010, Train Accuracy: 1.0000\n",
            "Validation Loss: 0.4427, Validation Accuracy: 0.8905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 25/30: 100%|██████████| 128/128 [55:22<00:00, 25.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/30], Train Loss: 0.0008, Train Accuracy: 0.9999\n",
            "Validation Loss: 0.4577, Validation Accuracy: 0.8863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 26/30: 100%|██████████| 128/128 [55:01<00:00, 25.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/30], Train Loss: 0.0008, Train Accuracy: 1.0000\n",
            "Validation Loss: 0.4933, Validation Accuracy: 0.8884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 27/30: 100%|██████████| 128/128 [52:58<00:00, 24.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/30], Train Loss: 0.0015, Train Accuracy: 0.9999\n",
            "Validation Loss: 0.5433, Validation Accuracy: 0.8989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 28/30: 100%|██████████| 128/128 [52:50<00:00, 24.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/30], Train Loss: 0.0291, Train Accuracy: 0.9942\n",
            "Validation Loss: 0.5506, Validation Accuracy: 0.8989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29/30: 100%|██████████| 128/128 [52:47<00:00, 24.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/30], Train Loss: 0.0335, Train Accuracy: 0.9870\n",
            "Validation Loss: 0.6011, Validation Accuracy: 0.8968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 30/30: 100%|██████████| 128/128 [52:39<00:00, 24.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30], Train Loss: 0.0044, Train Accuracy: 0.9994\n",
            "Validation Loss: 0.5507, Validation Accuracy: 0.8968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5."
      ],
      "metadata": {
        "id": "irW_7hQtZOrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best 모델 로드\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()  # 평가 모드로 설정"
      ],
      "metadata": {
        "id": "hwFgRhLs2W7b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}