{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOnkvOyJIBYR",
        "outputId": "2918a6f2-fce3-4475-ca80-c7ddec07c167"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 31 classes 분류"
      ],
      "metadata": {
        "id": "bJITfIaXYytr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 경로 설정(본인 드라이브에 맞게 수정)"
      ],
      "metadata": {
        "id": "aH9rrFiW1ez7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
        "import torch\n",
        "from tqdm import tqdm  # tqdm 불러오기\n",
        "\n",
        "# Train 데이터셋 경로 (processed_images와 원본 이미지파일)\n",
        "train_dir_1 = '/content/drive/MyDrive/mission_data/class_processed_images'\n",
        "train_dir_2 = '/content/drive/MyDrive/mission_data/class_training_images'\n",
        "\n",
        "# Val 데이터 경로 설정\n",
        "val_dir = '/content/drive/MyDrive/mission_data/class_validation_images'"
      ],
      "metadata": {
        "id": "VvI6gU4wfwFz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 정규화 및 증강(정규화 솔직히 차이 잘 모르겠음... 기존 평균, 표준편차로 돌려도 별 차이 없을 듯?)\n",
        "\n",
        "이 코드 빼고 사용해도 됨"
      ],
      "metadata": {
        "id": "UJmxmuoq43-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한번 돌리면 안돌려도 됨(결과 같음)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
        "import torch\n",
        "from tqdm import tqdm  # tqdm 불러오기\n",
        "\n",
        "# 이미지 로드 및 기본 전처리 (이미지 크기만 일단 조정)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# train 원본 데이터만 확인\n",
        "train_dataset_2 = datasets.ImageFolder(root=train_dir_2, transform=transform)\n",
        "\n",
        "# DataLoader 설정\n",
        "batch_size = 32\n",
        "origin_train_loader = DataLoader(train_dataset_2, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "# 평균과 표준편차 계산 함수에 tqdm 추가\n",
        "def calculate_mean_std(loader):\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    total_images_count = 0\n",
        "\n",
        "    # tqdm을 사용하여 진행 상황을 보여줌\n",
        "    for images, _ in tqdm(loader, desc=\"Calculating mean and std\"):\n",
        "        batch_samples = images.size(0)  # 배치 내 이미지 개수\n",
        "        images = images.view(batch_samples, images.size(1), -1)  # [batch_size, channels, height*width]\n",
        "        mean += images.mean(2).sum(0)\n",
        "        std += images.std(2).sum(0)\n",
        "        total_images_count += batch_samples\n",
        "\n",
        "    mean /= total_images_count\n",
        "    std /= total_images_count\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "# 평균과 표준편차 계산\n",
        "print(\"Calculating for train dataset...\")\n",
        "mean, std = calculate_mean_std(origin_train_loader)\n",
        "print(f\"Train Mean: {mean}\")\n",
        "print(f\"Train Standard Deviation: {std}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq35lQv1c3VW",
        "outputId": "8527c91c-6399-4041-cd7a-402ae41ba299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating for train dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating mean and std: 100%|██████████████████████████████████████████████████████| 128/128 [15:43<00:00,  7.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Mean: tensor([0.5498, 0.5226, 0.5052])\n",
            "Train Standard Deviation: tensor([0.2600, 0.2582, 0.2620])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 전처리 및 로드"
      ],
      "metadata": {
        "id": "-TbotnDukGWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "# 이미지 로드 및 기본 전처리 + 정규화\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5498, 0.5226, 0.5052], std=[0.2600, 0.2582, 0.2620])  # 계산한 평균, 표준편차를 활용한 정규화\n",
        "])\n",
        "\n",
        "# 증강을 추가한 transform\n",
        "augment_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=1),  # 좌우 반전\n",
        "    transforms.ColorJitter(saturation=0.3, brightness=0.3),  # 채도와 밝기 변환\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5498, 0.5226, 0.5052], std=[0.2600, 0.2582, 0.2620])\n",
        "])\n",
        "\n",
        "# 커스텀 데이터셋 클래스 정의\n",
        "class GenderStyleDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.gender_labels = []\n",
        "        self.style_labels = []\n",
        "        self.style_map = {}\n",
        "\n",
        "        # 클래스 폴더 이름을 숫자로 매핑 (0 ~ 30)\n",
        "        self.style_folders = sorted(os.listdir(root))\n",
        "        for idx, folder_name in enumerate(self.style_folders):\n",
        "            self.style_map[folder_name] = idx\n",
        "\n",
        "        # 데이터셋 로드 및 성별/스타일 라벨 생성\n",
        "        for folder_name in self.style_folders:\n",
        "            folder_path = os.path.join(root, folder_name)\n",
        "            if os.path.isdir(folder_path):\n",
        "                # 성별은 폴더명에서 W (여성) 또는 M (남성)으로 구분\n",
        "                gender = 0 if folder_name.startswith('W') else 1\n",
        "                style_label = self.style_map[folder_name]\n",
        "\n",
        "                for img_name in os.listdir(folder_path):\n",
        "                    img_path = os.path.join(folder_path, img_name)\n",
        "                    if img_name.endswith(('jpg', 'png')):\n",
        "                        self.image_paths.append(img_path)\n",
        "                        self.gender_labels.append(gender)\n",
        "                        self.style_labels.append(style_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        gender_label = torch.tensor(self.gender_labels[idx], dtype=torch.float32)  # 성별 레이블\n",
        "        style_label = torch.tensor(self.style_labels[idx], dtype=torch.long)        # 스타일 레이블\n",
        "\n",
        "        return image, gender_label, style_label\n",
        "\n",
        "    def get_style_name(self, style_label):\n",
        "        \"\"\"숫자 레이블을 스타일 이름으로 변환\"\"\"\n",
        "        for folder_name, label in self.style_map.items():\n",
        "            if label == style_label:\n",
        "                return folder_name\n",
        "        return None\n",
        "\n",
        "\n",
        "# 각 폴더에서 데이터셋 로드\n",
        "processed_datasets = GenderStyleDataset(root=train_dir_1, transform=transform)  # 전처리 데이터셋\n",
        "train_datasets =  GenderStyleDataset(root=train_dir_2, transform=transform)  # 원본 데이터셋\n",
        "augmented_datasets = GenderStyleDataset(root=train_dir_2, transform=augment_transform)  # 증강된 데이터셋\n",
        "\n",
        "# 데이터셋 합치기\n",
        "train_dataset = ConcatDataset([processed_datasets, train_datasets, augmented_datasets])\n",
        "\n",
        "# validation 데이터셋 로드\n",
        "val_dataset = GenderStyleDataset(root=val_dir, transform=transform)\n",
        "\n",
        "# DataLoader 설정\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
        "\n",
        "print(f\"Train size: {len(train_loader.dataset)}, Val size: {len(val_loader.dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5nmsSsx0gJ0",
        "outputId": "3058a094-c8e9-4e26-948b-0c6d2248994a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 12210, Val size: 951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋의 첫 번째 항목 확인\n",
        "image, gender_label, style_label = val_dataset[530]\n",
        "print(f\"Gender label: {gender_label}\")  # 0(여성), 1(남성)\n",
        "print(f\"Style label (numeric): {style_label}\")  # 0 ~ 30 중 하나의 숫자 레이블\n",
        "\n",
        "# 스타일 이름 확인\n",
        "style_name = val_dataset.get_style_name(style_label.item())\n",
        "print(f\"Style label (actual name): {style_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm8QytnlMYD-",
        "outputId": "b21ebfce-81fd-4f66-df28-ae555c3c9109"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender label: 0.0\n",
            "Style label (numeric): 8\n",
            "Style label (actual name): W_athleisure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "resnet-18 모델 정의 및 설정"
      ],
      "metadata": {
        "id": "KLdA1N4d5A4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Device 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class MultiOutputResNet(nn.Module):\n",
        "    def __init__(self, num_styles=31):  # 스타일 총 31개\n",
        "        super(MultiOutputResNet, self).__init__()\n",
        "        self.resnet = models.resnet18(weights=None)  # ResNet-18, pretrained=False\n",
        "        num_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Identity()  # ResNet의 Fully Connected 레이어를 제거하고 특징 추출만 수행\n",
        "\n",
        "        # 성별 분류 레이어 (이진 분류라서 출력 뉴런 수는 1)\n",
        "        self.gender_fc = nn.Linear(num_features, 1)\n",
        "\n",
        "        # 스타일 분류 레이어 (남성과 여성 스타일을 합친 31개)\n",
        "        self.style_fc = nn.Linear(num_features, num_styles)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 공통 특징 추출 (ResNet-18 사용)\n",
        "        features = self.resnet(x)\n",
        "\n",
        "        # 성별 분류\n",
        "        gender_output = torch.sigmoid(self.gender_fc(features))  # 시그모이드를 사용해 성별 확률을 계산\n",
        "\n",
        "        # 성별에 따른 스타일 분류 (전체 스타일 레이블을 사용하지만 이후 성별에 따라 제한)\n",
        "        style_output = self.style_fc(features)\n",
        "\n",
        "        return gender_output, style_output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWQVGOGDsTMx",
        "outputId": "9c334eae-2f48-45e6-d3d7-80a42bc95167"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "진행상황 저장 (이것도 본인 드라이브에 맞게 경로 수정)"
      ],
      "metadata": {
        "id": "Wj530Yak5GQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 체크포인트 저장 함수\n",
        "def save_checkpoint(state, filename=\"/content/drive/MyDrive/GSW/checkpoint_multi.pth\", weights_only=False):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "# 체크포인트 로드 함수\n",
        "def load_checkpoint(filename=\"/content/drive/MyDrive/GSW/checkpoint_multi.pth\", weights_only=False):\n",
        "    checkpoint = torch.load(filename)\n",
        "    epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    best_loss = checkpoint['best_loss']\n",
        "    return epoch, best_loss"
      ],
      "metadata": {
        "id": "m7b5FGp_sgIV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "resnet-18 학습모델"
      ],
      "metadata": {
        "id": "S9-tsKGl5KaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 및 검증 함수 정의\n",
        "def train_and_validate(model, train_loader, val_loader, gender_criterion, style_criterion, optimizer, scheduler, num_epochs, start_epoch=0, best_loss=float('inf')):\n",
        "    history = {\n",
        "        'train_gender_loss': [], 'train_style_loss': [], 'train_total_loss': [],\n",
        "        'val_gender_loss': [], 'val_style_loss': [], 'val_total_loss': [],\n",
        "        'train_gender_acc': [], 'train_style_acc': [], 'train_total_acc': [],\n",
        "        'val_gender_acc': [], 'val_style_acc': [], 'val_total_acc': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        model.train()\n",
        "        running_gender_loss = 0.0\n",
        "        running_style_loss = 0.0\n",
        "        running_total_loss = 0.0\n",
        "\n",
        "        correct_gender = 0\n",
        "        correct_style = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for images, gender_labels, style_labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
        "            images = images.to(device)\n",
        "            gender_labels = gender_labels.to(device)\n",
        "            style_labels = style_labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            gender_output, style_output = model(images)\n",
        "\n",
        "            # 성별 예측 손실 계산\n",
        "            loss_gender = gender_criterion(gender_output.view(-1), gender_labels.float())  # 성별 분류 손실\n",
        "\n",
        "            # 성별에 따른 스타일 손실 계산\n",
        "            loss_style = 0\n",
        "            for i in range(len(gender_labels)):\n",
        "                if gender_labels[i] == 0:  # 여성\n",
        "                    loss_style += style_criterion(style_output[i, 8:], style_labels[i] - 8)  # 8~30 스타일만 사용\n",
        "                else:  # 남성\n",
        "                    loss_style += style_criterion(style_output[i, :8], style_labels[i])  # 0~7 스타일만 사용\n",
        "\n",
        "            # 총 손실\n",
        "            total_loss = loss_gender + loss_style\n",
        "\n",
        "            # Backward pass 및 최적화\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_gender_loss += loss_gender.item()\n",
        "            running_style_loss += loss_style.item()\n",
        "            running_total_loss += total_loss.item()\n",
        "\n",
        "            # 정확도 계산\n",
        "            predicted_gender = (gender_output > 0.5).float().view(-1)\n",
        "            correct_gender += (predicted_gender == gender_labels).sum().item()\n",
        "\n",
        "            # 성별이 맞았을 때만 스타일 정확도 평가\n",
        "            for i in range(len(gender_labels)):\n",
        "                if predicted_gender[i] == gender_labels[i]:  # 성별이 맞았을 때만 스타일 평가\n",
        "                    if gender_labels[i] == 0:  # 여성\n",
        "                        predicted_style = torch.argmax(style_output[i, 8:]) + 8  # 8~30 스타일 중 예측\n",
        "                    else:  # 남성\n",
        "                        predicted_style = torch.argmax(style_output[i, :8])  # 0~7 스타일 중 예측\n",
        "\n",
        "                    correct_style += (predicted_style == style_labels[i]).sum().item()\n",
        "\n",
        "            total_samples += gender_labels.size(0)\n",
        "\n",
        "        # 평균 손실 및 정확도 계산\n",
        "        avg_gender_loss = running_gender_loss / len(train_loader)\n",
        "        avg_style_loss = running_style_loss / len(train_loader)\n",
        "        avg_total_loss = running_total_loss / len(train_loader)\n",
        "\n",
        "        gender_acc = correct_gender / total_samples\n",
        "        style_acc = correct_style / total_samples\n",
        "        total_acc = (correct_gender + correct_style) / (2 * total_samples)\n",
        "\n",
        "        # 기록\n",
        "        history['train_gender_loss'].append(avg_gender_loss)\n",
        "        history['train_style_loss'].append(avg_style_loss)\n",
        "        history['train_total_loss'].append(avg_total_loss)\n",
        "        history['train_gender_acc'].append(gender_acc)\n",
        "        history['train_style_acc'].append(style_acc)\n",
        "        history['train_total_acc'].append(total_acc)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Gender Loss: {avg_gender_loss:.4f}, Train Style Loss: {avg_style_loss:.4f}, Train Total Loss: {avg_total_loss:.4f}\")\n",
        "        print(f\"Train Gender Acc: {gender_acc:.4f}, Train Style Acc: {style_acc:.4f}, Train Total Acc: {total_acc:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_gender_loss = 0.0\n",
        "        val_running_style_loss = 0.0\n",
        "        val_running_total_loss = 0.0\n",
        "\n",
        "        val_correct_gender = 0\n",
        "        val_correct_style = 0\n",
        "        val_total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, gender_labels, style_labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\"):\n",
        "                images = images.to(device)\n",
        "                gender_labels = gender_labels.to(device)\n",
        "                style_labels = style_labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                gender_output, style_output = model(images)\n",
        "\n",
        "                # 성별 손실 계산\n",
        "                val_loss_gender = gender_criterion(gender_output.view(-1), gender_labels.float())\n",
        "\n",
        "                # 성별에 따른 스타일 손실 계산 (성별이 맞았을 때만)\n",
        "                val_loss_style = 0\n",
        "                for i in range(len(gender_labels)):\n",
        "                    if gender_labels[i] == 0:  # 여성\n",
        "                        val_loss_style += style_criterion(style_output[i, 8:], style_labels[i] - 8)  # 8~30 스타일만 사용\n",
        "                    else:  # 남성\n",
        "                        val_loss_style += style_criterion(style_output[i, :8], style_labels[i])  # 0~7 스타일만 사용\n",
        "\n",
        "                val_total_loss = val_loss_gender + val_loss_style\n",
        "                val_running_gender_loss += val_loss_gender.item()\n",
        "                val_running_style_loss += val_loss_style.item()\n",
        "                val_running_total_loss += val_total_loss.item()\n",
        "\n",
        "                # 성별이 맞았을 때만 스타일 정확도 평가\n",
        "                val_predicted_gender = (gender_output > 0.5).float().view(-1)\n",
        "                val_correct_gender += (val_predicted_gender == gender_labels).sum().item()\n",
        "\n",
        "                for i in range(len(gender_labels)):\n",
        "                    if val_predicted_gender[i] == gender_labels[i]:  # 성별이 맞았을 때만 스타일 평가\n",
        "                        if gender_labels[i] == 0:  # 여성\n",
        "                            val_predicted_style = torch.argmax(style_output[i, 8:]) + 8  # 8~30 스타일 중 예측\n",
        "                        else:  # 남성\n",
        "                            val_predicted_style = torch.argmax(style_output[i, :8])  # 0~7 스타일 중 예측\n",
        "\n",
        "                        val_correct_style += (val_predicted_style == style_labels[i]).sum().item()\n",
        "\n",
        "                val_total_samples += gender_labels.size(0)\n",
        "\n",
        "        # Validation 손실 및 정확도 평균\n",
        "        avg_val_gender_loss = val_running_gender_loss / len(val_loader)\n",
        "        avg_val_style_loss = val_running_style_loss / len(val_loader)\n",
        "        avg_val_total_loss = val_running_total_loss / len(val_loader)\n",
        "\n",
        "        val_gender_acc = val_correct_gender / val_total_samples\n",
        "        val_style_acc = val_correct_style / val_total_samples\n",
        "        val_total_acc = (val_correct_gender + val_correct_style) / (2 * val_total_samples)\n",
        "\n",
        "        # 기록\n",
        "        history['val_gender_loss'].append(avg_val_gender_loss)\n",
        "        history['val_style_loss'].append(avg_val_style_loss)\n",
        "        history['val_total_loss'].append(avg_val_total_loss)\n",
        "        history['val_gender_acc'].append(val_gender_acc)\n",
        "        history['val_style_acc'].append(val_style_acc)\n",
        "        history['val_total_acc'].append(val_total_acc)\n",
        "\n",
        "        print(f\"Validation Gender Loss: {avg_val_gender_loss:.4f}, Validation Style Loss: {avg_val_style_loss:.4f}, Validation Total Loss: {avg_val_total_loss:.4f}\")\n",
        "        print(f\"Validation Gender Acc: {val_gender_acc:.4f}, Validation Style Acc: {val_style_acc:.4f}, Validation Total Acc: {val_total_acc:.4f}\")\n",
        "\n",
        "        # ReduceLROnPlateau 스케줄러를 사용하여 학습률 조정 (총 손실 기준)\n",
        "        scheduler.step(avg_val_total_loss)\n",
        "        current_lr = scheduler.optimizer.param_groups[0]['lr']  # 현재 학습률 확인\n",
        "        print(f\"Current Learning Rate: {current_lr}\")\n",
        "\n",
        "        # 가장 낮은 총 손실을 가진 모델 저장\n",
        "        if avg_val_total_loss < best_loss:\n",
        "            best_loss = avg_val_total_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "            # 체크포인트 저장\n",
        "            save_checkpoint({\n",
        "                'epoch': epoch + 1,  # 현재 에폭 저장\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'best_loss': best_loss\n",
        "            })\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "x0pN9Xs8soTH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터 설정 및 학습"
      ],
      "metadata": {
        "id": "Cdl5Wu_9GxDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "learning_rate = 0.01\n",
        "num_epochs = 100\n",
        "\n",
        "# 모델 정의 (MultiOutputResNet 모델)\n",
        "model = MultiOutputResNet(num_styles=31).to(device)\n",
        "\n",
        "# Loss 및 Optimizer 설정\n",
        "gender_criterion = nn.BCEWithLogitsLoss()  # 성별 이진 분류를 위한 손실 함수\n",
        "style_criterion = nn.CrossEntropyLoss()  # 스타일 분류 손실은 다중 클래스 분류\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)  # AdamW 옵티마이저 사용\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "\n",
        "\n",
        "# 학습 재개를 위한 체크포인트 로드\n",
        "try:\n",
        "    start_epoch, best_loss = load_checkpoint()\n",
        "    print(f\"Checkpoint loaded. Resuming from epoch {start_epoch} with lowest loss {best_loss:.4f}.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"No checkpoint found, starting from scratch.\")\n",
        "    start_epoch, best_loss = 0, float('inf')\n",
        "\n",
        "# 학습 및 검증 시작\n",
        "history = train_and_validate(model, train_loader, val_loader, gender_criterion, style_criterion, optimizer, scheduler, num_epochs, start_epoch, best_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qLe3Pjuet4oq",
        "outputId": "0a8d1ed1-68f2-4637-d6b3-b56dafef63c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-fcdbf664069f>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found, starting from scratch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1/100: 100%|██████████| 382/382 [23:21<00:00,  3.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Train Gender Loss: 0.6884, Train Style Loss: 82.6726, Train Total Loss: 83.3610\n",
            "Train Gender Acc: 0.4482, Train Style Acc: 0.0347, Train Total Acc: 0.2414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 1/100: 100%|██████████| 30/30 [02:10<00:00,  4.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6906, Validation Style Loss: 79.9396, Validation Total Loss: 80.6302\n",
            "Validation Gender Acc: 0.4479, Validation Style Acc: 0.0463, Validation Total Acc: 0.2471\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2/100: 100%|██████████| 382/382 [14:18<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/100], Train Gender Loss: 0.6882, Train Style Loss: 79.9257, Train Total Loss: 80.6139\n",
            "Train Gender Acc: 0.4477, Train Style Acc: 0.0376, Train Total Acc: 0.2426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 2/100: 100%|██████████| 30/30 [00:59<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6887, Validation Style Loss: 79.9504, Validation Total Loss: 80.6391\n",
            "Validation Gender Acc: 0.4479, Validation Style Acc: 0.0484, Validation Total Acc: 0.2482\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3/100: 100%|██████████| 382/382 [14:25<00:00,  2.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/100], Train Gender Loss: 0.6875, Train Style Loss: 79.8882, Train Total Loss: 80.5757\n",
            "Train Gender Acc: 0.4477, Train Style Acc: 0.0366, Train Total Acc: 0.2421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 3/100: 100%|██████████| 30/30 [01:00<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6881, Validation Style Loss: 79.3782, Validation Total Loss: 80.0664\n",
            "Validation Gender Acc: 0.4479, Validation Style Acc: 0.0557, Validation Total Acc: 0.2518\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4/100: 100%|██████████| 382/382 [15:17<00:00,  2.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/100], Train Gender Loss: 0.6877, Train Style Loss: 79.8525, Train Total Loss: 80.5402\n",
            "Train Gender Acc: 0.4477, Train Style Acc: 0.0414, Train Total Acc: 0.2446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 4/100: 100%|██████████| 30/30 [01:04<00:00,  2.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6885, Validation Style Loss: 79.7062, Validation Total Loss: 80.3947\n",
            "Validation Gender Acc: 0.4479, Validation Style Acc: 0.0305, Validation Total Acc: 0.2392\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5/100: 100%|██████████| 382/382 [16:16<00:00,  2.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/100], Train Gender Loss: 0.6874, Train Style Loss: 79.8098, Train Total Loss: 80.4972\n",
            "Train Gender Acc: 0.4475, Train Style Acc: 0.0399, Train Total Acc: 0.2437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 5/100: 100%|██████████| 30/30 [01:14<00:00,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6877, Validation Style Loss: 79.5857, Validation Total Loss: 80.2734\n",
            "Validation Gender Acc: 0.4479, Validation Style Acc: 0.0484, Validation Total Acc: 0.2482\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 6/100: 100%|██████████| 382/382 [16:13<00:00,  2.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/100], Train Gender Loss: 0.6875, Train Style Loss: 79.7313, Train Total Loss: 80.4188\n",
            "Train Gender Acc: 0.4483, Train Style Acc: 0.0392, Train Total Acc: 0.2438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 6/100: 100%|██████████| 30/30 [01:04<00:00,  2.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6860, Validation Style Loss: 79.3721, Validation Total Loss: 80.0581\n",
            "Validation Gender Acc: 0.4501, Validation Style Acc: 0.0326, Validation Total Acc: 0.2413\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 7/100: 100%|██████████| 382/382 [14:55<00:00,  2.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/100], Train Gender Loss: 0.6872, Train Style Loss: 79.6765, Train Total Loss: 80.3637\n",
            "Train Gender Acc: 0.4483, Train Style Acc: 0.0405, Train Total Acc: 0.2444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 7/100: 100%|██████████| 30/30 [01:03<00:00,  2.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6864, Validation Style Loss: 79.6127, Validation Total Loss: 80.2991\n",
            "Validation Gender Acc: 0.4774, Validation Style Acc: 0.0641, Validation Total Acc: 0.2708\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 8/100: 100%|██████████| 382/382 [14:55<00:00,  2.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/100], Train Gender Loss: 0.6868, Train Style Loss: 79.5761, Train Total Loss: 80.2629\n",
            "Train Gender Acc: 0.4480, Train Style Acc: 0.0408, Train Total Acc: 0.2444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 8/100: 100%|██████████| 30/30 [01:03<00:00,  2.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6859, Validation Style Loss: 78.6667, Validation Total Loss: 79.3526\n",
            "Validation Gender Acc: 0.4669, Validation Style Acc: 0.0620, Validation Total Acc: 0.2645\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 9/100: 100%|██████████| 382/382 [14:08<00:00,  2.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/100], Train Gender Loss: 0.6866, Train Style Loss: 79.5606, Train Total Loss: 80.2472\n",
            "Train Gender Acc: 0.4507, Train Style Acc: 0.0416, Train Total Acc: 0.2462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 9/100: 100%|██████████| 30/30 [01:00<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6869, Validation Style Loss: 78.7565, Validation Total Loss: 79.4434\n",
            "Validation Gender Acc: 0.4479, Validation Style Acc: 0.0515, Validation Total Acc: 0.2497\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 10/100: 100%|██████████| 382/382 [14:04<00:00,  2.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Train Gender Loss: 0.6868, Train Style Loss: 79.4796, Train Total Loss: 80.1664\n",
            "Train Gender Acc: 0.4492, Train Style Acc: 0.0405, Train Total Acc: 0.2449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 10/100: 100%|██████████| 30/30 [01:00<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6863, Validation Style Loss: 78.6605, Validation Total Loss: 79.3468\n",
            "Validation Gender Acc: 0.4479, Validation Style Acc: 0.0589, Validation Total Acc: 0.2534\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 11/100: 100%|██████████| 382/382 [14:26<00:00,  2.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/100], Train Gender Loss: 0.6866, Train Style Loss: 79.3893, Train Total Loss: 80.0760\n",
            "Train Gender Acc: 0.4490, Train Style Acc: 0.0429, Train Total Acc: 0.2459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 11/100: 100%|██████████| 30/30 [01:01<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6847, Validation Style Loss: 78.7111, Validation Total Loss: 79.3958\n",
            "Validation Gender Acc: 0.4501, Validation Style Acc: 0.0599, Validation Total Acc: 0.2550\n",
            "Current Learning Rate: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 12/100: 100%|██████████| 382/382 [14:05<00:00,  2.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/100], Train Gender Loss: 0.6863, Train Style Loss: 79.3087, Train Total Loss: 79.9950\n",
            "Train Gender Acc: 0.4491, Train Style Acc: 0.0426, Train Total Acc: 0.2459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 12/100: 100%|██████████| 30/30 [01:00<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6856, Validation Style Loss: 78.8224, Validation Total Loss: 79.5080\n",
            "Validation Gender Acc: 0.4479, Validation Style Acc: 0.0578, Validation Total Acc: 0.2529\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 13/100: 100%|██████████| 382/382 [14:02<00:00,  2.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/100], Train Gender Loss: 0.6854, Train Style Loss: 78.9329, Train Total Loss: 79.6183\n",
            "Train Gender Acc: 0.4496, Train Style Acc: 0.0470, Train Total Acc: 0.2483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 13/100: 100%|██████████| 30/30 [01:00<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6851, Validation Style Loss: 78.1897, Validation Total Loss: 78.8747\n",
            "Validation Gender Acc: 0.4479, Validation Style Acc: 0.0620, Validation Total Acc: 0.2550\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 14/100: 100%|██████████| 382/382 [13:48<00:00,  2.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/100], Train Gender Loss: 0.6840, Train Style Loss: 78.6320, Train Total Loss: 79.3160\n",
            "Train Gender Acc: 0.4511, Train Style Acc: 0.0472, Train Total Acc: 0.2491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 14/100: 100%|██████████| 30/30 [00:59<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6825, Validation Style Loss: 78.1306, Validation Total Loss: 78.8131\n",
            "Validation Gender Acc: 0.4585, Validation Style Acc: 0.0631, Validation Total Acc: 0.2608\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 15/100: 100%|██████████| 382/382 [14:56<00:00,  2.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/100], Train Gender Loss: 0.6830, Train Style Loss: 78.1833, Train Total Loss: 78.8662\n",
            "Train Gender Acc: 0.4616, Train Style Acc: 0.0544, Train Total Acc: 0.2580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 15/100: 100%|██████████| 30/30 [01:06<00:00,  2.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6783, Validation Style Loss: 76.9614, Validation Total Loss: 77.6397\n",
            "Validation Gender Acc: 0.4711, Validation Style Acc: 0.0810, Validation Total Acc: 0.2760\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 16/100: 100%|██████████| 382/382 [14:59<00:00,  2.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/100], Train Gender Loss: 0.6791, Train Style Loss: 77.6816, Train Total Loss: 78.3608\n",
            "Train Gender Acc: 0.4941, Train Style Acc: 0.0663, Train Total Acc: 0.2802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 16/100: 100%|██████████| 30/30 [01:03<00:00,  2.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6758, Validation Style Loss: 77.1843, Validation Total Loss: 77.8601\n",
            "Validation Gender Acc: 0.5174, Validation Style Acc: 0.0810, Validation Total Acc: 0.2992\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 17/100: 100%|██████████| 382/382 [15:00<00:00,  2.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/100], Train Gender Loss: 0.6770, Train Style Loss: 76.8957, Train Total Loss: 77.5727\n",
            "Train Gender Acc: 0.5142, Train Style Acc: 0.0722, Train Total Acc: 0.2932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 17/100: 100%|██████████| 30/30 [01:04<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6727, Validation Style Loss: 75.9180, Validation Total Loss: 76.5907\n",
            "Validation Gender Acc: 0.5195, Validation Style Acc: 0.0852, Validation Total Acc: 0.3023\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 18/100: 100%|██████████| 382/382 [15:24<00:00,  2.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/100], Train Gender Loss: 0.6750, Train Style Loss: 75.8160, Train Total Loss: 76.4911\n",
            "Train Gender Acc: 0.5219, Train Style Acc: 0.0859, Train Total Acc: 0.3039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 18/100: 100%|██████████| 30/30 [01:13<00:00,  2.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6688, Validation Style Loss: 76.6706, Validation Total Loss: 77.3394\n",
            "Validation Gender Acc: 0.5121, Validation Style Acc: 0.0873, Validation Total Acc: 0.2997\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 19/100: 100%|██████████| 382/382 [17:01<00:00,  2.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/100], Train Gender Loss: 0.6749, Train Style Loss: 73.9410, Train Total Loss: 74.6158\n",
            "Train Gender Acc: 0.5230, Train Style Acc: 0.0964, Train Total Acc: 0.3097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 19/100: 100%|██████████| 30/30 [01:14<00:00,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6698, Validation Style Loss: 76.0202, Validation Total Loss: 76.6900\n",
            "Validation Gender Acc: 0.5647, Validation Style Acc: 0.1073, Validation Total Acc: 0.3360\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 20/100: 100%|██████████| 382/382 [16:25<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/100], Train Gender Loss: 0.6725, Train Style Loss: 72.0544, Train Total Loss: 72.7270\n",
            "Train Gender Acc: 0.5347, Train Style Acc: 0.1061, Train Total Acc: 0.3204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 20/100: 100%|██████████| 30/30 [01:03<00:00,  2.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6671, Validation Style Loss: 74.1203, Validation Total Loss: 74.7874\n",
            "Validation Gender Acc: 0.5426, Validation Style Acc: 0.1167, Validation Total Acc: 0.3297\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 21/100: 100%|██████████| 382/382 [14:33<00:00,  2.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/100], Train Gender Loss: 0.6712, Train Style Loss: 69.5564, Train Total Loss: 70.2276\n",
            "Train Gender Acc: 0.5420, Train Style Acc: 0.1262, Train Total Acc: 0.3341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 21/100: 100%|██████████| 30/30 [01:02<00:00,  2.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6737, Validation Style Loss: 73.5008, Validation Total Loss: 74.1745\n",
            "Validation Gender Acc: 0.5058, Validation Style Acc: 0.1094, Validation Total Acc: 0.3076\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 22/100: 100%|██████████| 382/382 [14:37<00:00,  2.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/100], Train Gender Loss: 0.6710, Train Style Loss: 66.2388, Train Total Loss: 66.9098\n",
            "Train Gender Acc: 0.5395, Train Style Acc: 0.1450, Train Total Acc: 0.3422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 22/100: 100%|██████████| 30/30 [01:03<00:00,  2.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6637, Validation Style Loss: 70.9861, Validation Total Loss: 71.6498\n",
            "Validation Gender Acc: 0.6015, Validation Style Acc: 0.1661, Validation Total Acc: 0.3838\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 23/100: 100%|██████████| 382/382 [14:20<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/100], Train Gender Loss: 0.6714, Train Style Loss: 61.5674, Train Total Loss: 62.2387\n",
            "Train Gender Acc: 0.5382, Train Style Acc: 0.1755, Train Total Acc: 0.3568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 23/100: 100%|██████████| 30/30 [01:00<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6714, Validation Style Loss: 67.3717, Validation Total Loss: 68.0431\n",
            "Validation Gender Acc: 0.6120, Validation Style Acc: 0.2029, Validation Total Acc: 0.4075\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 24/100: 100%|██████████| 382/382 [14:03<00:00,  2.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/100], Train Gender Loss: 0.6715, Train Style Loss: 54.0372, Train Total Loss: 54.7087\n",
            "Train Gender Acc: 0.5409, Train Style Acc: 0.2159, Train Total Acc: 0.3784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 24/100: 100%|██████████| 30/30 [01:01<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6626, Validation Style Loss: 63.5927, Validation Total Loss: 64.2553\n",
            "Validation Gender Acc: 0.5857, Validation Style Acc: 0.2355, Validation Total Acc: 0.4106\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 25/100: 100%|██████████| 382/382 [14:20<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/100], Train Gender Loss: 0.6709, Train Style Loss: 44.3085, Train Total Loss: 44.9794\n",
            "Train Gender Acc: 0.5446, Train Style Acc: 0.2792, Train Total Acc: 0.4119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 25/100: 100%|██████████| 30/30 [01:01<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6683, Validation Style Loss: 62.2873, Validation Total Loss: 62.9556\n",
            "Validation Gender Acc: 0.5100, Validation Style Acc: 0.2355, Validation Total Acc: 0.3728\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 26/100: 100%|██████████| 382/382 [14:30<00:00,  2.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/100], Train Gender Loss: 0.6704, Train Style Loss: 33.6901, Train Total Loss: 34.3606\n",
            "Train Gender Acc: 0.5399, Train Style Acc: 0.3471, Train Total Acc: 0.4435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 26/100: 100%|██████████| 30/30 [01:02<00:00,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6708, Validation Style Loss: 62.5961, Validation Total Loss: 63.2670\n",
            "Validation Gender Acc: 0.5321, Validation Style Acc: 0.2923, Validation Total Acc: 0.4122\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 27/100: 100%|██████████| 382/382 [14:35<00:00,  2.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/100], Train Gender Loss: 0.6715, Train Style Loss: 23.5235, Train Total Loss: 24.1951\n",
            "Train Gender Acc: 0.5477, Train Style Acc: 0.4117, Train Total Acc: 0.4797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 27/100: 100%|██████████| 30/30 [01:02<00:00,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6691, Validation Style Loss: 72.7610, Validation Total Loss: 73.4301\n",
            "Validation Gender Acc: 0.5405, Validation Style Acc: 0.3039, Validation Total Acc: 0.4222\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 28/100: 100%|██████████| 382/382 [14:35<00:00,  2.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/100], Train Gender Loss: 0.6692, Train Style Loss: 16.3858, Train Total Loss: 17.0550\n",
            "Train Gender Acc: 0.5505, Train Style Acc: 0.4604, Train Total Acc: 0.5055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Epoch 28/100: 100%|██████████| 30/30 [01:03<00:00,  2.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gender Loss: 0.6611, Validation Style Loss: 66.4254, Validation Total Loss: 67.0865\n",
            "Validation Gender Acc: 0.5626, Validation Style Acc: 0.3470, Validation Total Acc: 0.4548\n",
            "Current Learning Rate: 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29/100:  29%|██▉       | 112/382 [04:17<10:20,  2.30s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-76cde8720b3e>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# 학습 및 검증 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-6edbb9696d58>\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, val_loader, gender_criterion, style_criterion, optimizer, scheduler, num_epochs, start_epoch, best_loss)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Training Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mgender_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgender_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 체크포인트 저장된 모델 사용할거면 아래 코드 경로 수정하여 사용\n",
        "load_checkpoint(filename=\"C:/Users/SW/Desktop/데크캠/mission1-2/checkpoint_multi.pth\", weights_only=False)\n",
        "\n",
        "\n",
        "def evaluate_with_misclassifications(model, test_loader, criterion, num_classes, class_labels, test_dataset):\n",
        "    model.eval()  # 모델을 평가 모드로 전환\n",
        "    test_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # 클래스별 정확도를 계산하기 위한 변수\n",
        "    correct_per_class = [0] * num_classes  # 각 클래스별로 맞은 개수를 저장\n",
        "    total_per_class = [0] * num_classes    # 각 클래스별로 총 샘플 수를 저장\n",
        "\n",
        "    # 잘못 분류된 샘플 기록\n",
        "    misclassified = {i: [] for i in range(num_classes)}  # 각 클래스별로 잘못 분류된 샘플 기록\n",
        "\n",
        "    # no_grad 사용\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(tqdm(test_loader, desc=\"Evaluating\")):  # images와 labels만 사용\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # 모델에 입력 후 출력 계산\n",
        "            outputs = model(images)\n",
        "\n",
        "            # 손실 계산\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # 정확도 계산\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "            # 각 클래스별 맞은 개수와 총 샘플 수 추적\n",
        "            for j in range(len(labels)):\n",
        "                label = labels[j].item()\n",
        "                pred = predicted[j].item()\n",
        "\n",
        "                # 잘못 분류된 경우 기록\n",
        "                if label != pred:\n",
        "                    img_path = test_dataset.samples[i * test_loader.batch_size + j][0]  # 파일 경로 추출\n",
        "                    misclassified[label].append((img_path, pred))\n",
        "\n",
        "                # 정확한 예측일 경우\n",
        "                if label == pred:\n",
        "                    correct_per_class[label] += 1\n",
        "                total_per_class[label] += 1\n",
        "\n",
        "    # 평균 손실 및 전체 정확도 계산\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    overall_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    # 클래스별 정확도 계산\n",
        "    class_accuracy = []\n",
        "    for i in range(num_classes):\n",
        "        if total_per_class[i] > 0:\n",
        "            accuracy = correct_per_class[i] / total_per_class[i]\n",
        "        else:\n",
        "            accuracy = 0.0\n",
        "        class_accuracy.append(accuracy)\n",
        "\n",
        "    # 결과 출력 (클래스 라벨과 함께)\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Overall Test Accuracy: {overall_accuracy:.4f}\")\n",
        "    for i, acc in enumerate(class_accuracy):\n",
        "        print(f\"{class_labels[i]}: Accuracy = {acc:.4f}\")\n",
        "\n",
        "    return avg_loss, overall_accuracy, class_accuracy, misclassified\n",
        "\n",
        "\n",
        "test_loader = val_loader\n",
        "num_classes = 31\n",
        "class_labels = train_dataset_2.classes\n",
        "test_dataset = val_dataset\n",
        "\n",
        "avg_loss, overall_accuracy, class_accuracy, misclassified = evaluate_with_misclassifications(model, test_loader, criterion, num_classes, class_labels, test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm01pK2nFGql",
        "outputId": "be77e403-1cd5-455c-cbc9-150d5499e6c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [02:12<00:00,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.3989, Overall Test Accuracy: 0.5489\n",
            "M_bold: Accuracy = 0.5614\n",
            "M_hiphop: Accuracy = 0.5000\n",
            "M_hippie: Accuracy = 0.6098\n",
            "M_ivy: Accuracy = 0.6329\n",
            "M_metrosexual: Accuracy = 0.4828\n",
            "M_mods: Accuracy = 0.5875\n",
            "M_normcore: Accuracy = 0.0980\n",
            "M_sportivecasual: Accuracy = 0.4423\n",
            "W_athleisure: Accuracy = 0.6429\n",
            "W_bodyconscious: Accuracy = 0.6522\n",
            "W_cityglam: Accuracy = 0.5000\n",
            "W_classic: Accuracy = 0.6818\n",
            "W_disco: Accuracy = 0.4000\n",
            "W_ecology: Accuracy = 0.5294\n",
            "W_feminine: Accuracy = 0.7273\n",
            "W_genderless: Accuracy = 0.7500\n",
            "W_grunge: Accuracy = 0.6000\n",
            "W_hiphop: Accuracy = 0.5000\n",
            "W_hippie: Accuracy = 0.5714\n",
            "W_kitsch: Accuracy = 0.5909\n",
            "W_lingerie: Accuracy = 0.6000\n",
            "W_lounge: Accuracy = 0.1250\n",
            "W_military: Accuracy = 0.4444\n",
            "W_minimal: Accuracy = 0.5429\n",
            "W_normcore: Accuracy = 0.2500\n",
            "W_oriental: Accuracy = 0.6667\n",
            "W_popart: Accuracy = 0.7500\n",
            "W_powersuit: Accuracy = 0.7353\n",
            "W_punk: Accuracy = 0.3333\n",
            "W_space: Accuracy = 0.6000\n",
            "W_sportivecasual: Accuracy = 0.6875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 지정된 클래스에서 잘못 분류된 샘플 출력\n",
        "target_class = 'M_normcore'\n",
        "target_class_index = class_labels.index(target_class)\n",
        "\n",
        "if len(misclassified[target_class_index]) > 0:\n",
        "    print(f\"\\nMisclassifications for class '{target_class}':\")\n",
        "    for img_path, pred_class in misclassified[target_class_index]:\n",
        "        file_name = os.path.basename(img_path)  # 파일명만 추출\n",
        "        print(f\"File: {file_name} misclassified as {class_labels[pred_class]}\")\n",
        "else:\n",
        "    print(f\"\\nNo misclassifications for class '{target_class}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXzEoN2OHZ15",
        "outputId": "4616bef9-79ac-48e8-9f0e-8bdd7a041b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Misclassifications for class 'M_normcore':\n",
            "File: W_00117_19_normcore_M.jpg misclassified as M_metrosexual\n",
            "File: W_00551_19_normcore_M.jpg misclassified as M_ivy\n",
            "File: W_00831_19_normcore_M.jpg misclassified as M_sportivecasual\n",
            "File: W_01410_19_normcore_M.jpg misclassified as M_sportivecasual\n",
            "File: W_01552_19_normcore_M.jpg misclassified as M_hippie\n",
            "File: W_02705_19_normcore_M.jpg misclassified as W_hippie\n",
            "File: W_03003_19_normcore_M.jpg misclassified as M_hiphop\n",
            "File: W_06609_19_normcore_M.jpg misclassified as M_metrosexual\n",
            "File: W_06860_19_normcore_M.jpg misclassified as W_ecology\n",
            "File: W_06917_19_normcore_M.jpg misclassified as M_metrosexual\n",
            "File: W_06966_19_normcore_M.jpg misclassified as M_sportivecasual\n",
            "File: W_07058_19_normcore_M.jpg misclassified as M_metrosexual\n",
            "File: W_07077_19_normcore_M.jpg misclassified as W_hiphop\n",
            "File: W_07120_19_normcore_M.jpg misclassified as M_bold\n",
            "File: W_10103_19_normcore_M.jpg misclassified as M_mods\n",
            "File: W_12412_19_normcore_M.jpg misclassified as M_hippie\n",
            "File: W_12847_19_normcore_M.jpg misclassified as W_disco\n",
            "File: W_12880_19_normcore_M.jpg misclassified as M_sportivecasual\n",
            "File: W_15662_19_normcore_M.jpg misclassified as M_bold\n",
            "File: W_16037_19_normcore_M.jpg misclassified as M_hippie\n",
            "File: W_16848_19_normcore_M.jpg misclassified as W_cityglam\n",
            "File: W_16960_19_normcore_M.jpg misclassified as M_hiphop\n",
            "File: W_17058_19_normcore_M.jpg misclassified as M_bold\n",
            "File: W_17062_19_normcore_M.jpg misclassified as M_metrosexual\n",
            "File: W_17239_19_normcore_M.jpg misclassified as M_hiphop\n",
            "File: W_17366_19_normcore_M.jpg misclassified as M_ivy\n",
            "File: W_17478_19_normcore_M.jpg misclassified as M_metrosexual\n",
            "File: W_17767_19_normcore_M.jpg misclassified as M_sportivecasual\n",
            "File: W_17967_19_normcore_M.jpg misclassified as M_bold\n",
            "File: W_23899_19_normcore_M.jpg misclassified as W_oriental\n",
            "File: W_24556_19_normcore_M.jpg misclassified as M_bold\n",
            "File: W_25649_19_normcore_M.jpg misclassified as W_lounge\n",
            "File: W_26099_19_normcore_M.jpg misclassified as M_hiphop\n",
            "File: W_26120_19_normcore_M.jpg misclassified as M_sportivecasual\n",
            "File: W_28141_19_normcore_M.jpg misclassified as M_bold\n",
            "File: W_28909_19_normcore_M.jpg misclassified as W_punk\n",
            "File: W_29693_19_normcore_M.jpg misclassified as M_bold\n",
            "File: W_29918_19_normcore_M.jpg misclassified as M_bold\n",
            "File: W_30223_19_normcore_M.jpg misclassified as W_athleisure\n",
            "File: W_31439_19_normcore_M.jpg misclassified as M_sportivecasual\n",
            "File: W_31478_19_normcore_M.jpg misclassified as W_disco\n",
            "File: W_31823_19_normcore_M.jpg misclassified as M_ivy\n",
            "File: W_32314_19_normcore_M.jpg misclassified as M_metrosexual\n",
            "File: W_32385_19_normcore_M.jpg misclassified as W_athleisure\n",
            "File: W_50836_19_normcore_M.jpg misclassified as M_bold\n",
            "File: W_54129_19_normcore_M.jpg misclassified as W_ecology\n"
          ]
        }
      ]
    }
  ]
}