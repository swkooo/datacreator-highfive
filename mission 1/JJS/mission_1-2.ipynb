{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHYCyb3PwVN_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import fnmatch\n",
        "import datetime\n",
        "import pickle\n",
        "import numpy as np\n",
        "import cv2\n",
        "from imgaug import augmenters as img_aug\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일들을 data 디렉토리로 이동\n",
        "import shutil\n",
        "os.makedirs('data', exist_ok=True)\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, 'data/' + filename)\n",
        "\n",
        "class FashionStyleClassifier:\n",
        "    def __init__(self):\n",
        "        data_dir = 'data'\n",
        "        file_list = os.listdir(data_dir)\n",
        "        image_paths = []\n",
        "        labels = []\n",
        "        pattern = \"*.jpg\"\n",
        "        self.model_output_dir = 'output'\n",
        "        os.makedirs(self.model_output_dir, exist_ok=True)\n",
        "        for filename in file_list:\n",
        "            if fnmatch.fnmatch(filename, pattern):\n",
        "                image_paths.append(os.path.join(data_dir, filename))\n",
        "                label = filename.split('_')[2]  # 스타일 라벨 추출\n",
        "                labels.append(label)\n",
        "\n",
        "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(image_paths, labels, test_size=0.2)\n",
        "        print(\"Training data: %d\\nValidation data: %d\" % (len(self.X_train), len(self.X_valid)))\n",
        "\n",
        "    def random_augment(self, image):\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = self.pan(image)\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = self.zoom(image)\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = self.blur(image)\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = self.adjust_brightness(image)\n",
        "        return image\n",
        "\n",
        "    def my_imread(self, image_path):\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        return image\n",
        "\n",
        "    def zoom(self, image):\n",
        "        zoom = img_aug.Affine(scale=(1, 1.3))\n",
        "        image = zoom.augment_image(image)\n",
        "        return image\n",
        "\n",
        "    def pan(self, image):\n",
        "        pan = img_aug.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
        "        image = pan.augment_image(image)\n",
        "        return image\n",
        "\n",
        "    def adjust_brightness(self, image):\n",
        "        brightness = img_aug.Multiply((0.7, 1.3))\n",
        "        image = brightness.augment_image(image)\n",
        "        return image\n",
        "\n",
        "    def blur(self, image):\n",
        "        kernel_size = random.randint(1, 5)\n",
        "        image = cv2.blur(image, (kernel_size, kernel_size))\n",
        "        return image\n",
        "\n",
        "    def img_preprocess(self, image):\n",
        "        height, _, _ = image.shape\n",
        "        image = image[int(height/2):, :, :]\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
        "        image = cv2.GaussianBlur(image, (3, 3), 0)\n",
        "        image = cv2.resize(image, (200, 66))\n",
        "        image = image / 255\n",
        "        return image\n",
        "\n",
        "    def resnet18_model(self, num_classes):\n",
        "        # ResNet-18 모델 정의\n",
        "        model = Sequential(name='ResNet18_Fashion_Classifier')\n",
        "        model.add(Conv2D(64, (7, 7), strides=(2, 2), input_shape=(66, 200, 3), activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "        optimizer = Adam(lr=1e-4)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def image_data_generator(self, image_paths, labels, batch_size, is_training):\n",
        "        while True:\n",
        "            batch_images = []\n",
        "            batch_labels = []\n",
        "            for i in range(batch_size):\n",
        "                random_index = random.randint(0, len(image_paths) - 1)\n",
        "                image_path = image_paths[random_index]\n",
        "                image = self.my_imread(image_paths[random_index])\n",
        "                label = labels[random_index]\n",
        "                if is_training:\n",
        "                    image = self.random_augment(image)\n",
        "                image = self.img_preprocess(image)\n",
        "                batch_images.append(image)\n",
        "                batch_labels.append(label)\n",
        "            yield np.asarray(batch_images), np.asarray(batch_labels)\n",
        "\n",
        "    def train(self, num_classes):\n",
        "        model = self.resnet18_model(num_classes)\n",
        "        print(model.summary())\n",
        "        checkpoint_callback = ModelCheckpoint(filepath=os.path.join(self.model_output_dir, 'best_model.h5'), verbose=1, save_best_only=True)\n",
        "\n",
        "        history = model.fit(\n",
        "            self.image_data_generator(self.X_train, self.y_train, batch_size=32, is_training=True),\n",
        "            steps_per_epoch=200,\n",
        "            epochs=50,\n",
        "            validation_data=self.image_data_generator(self.X_valid, self.y_valid, batch_size=32, is_training=False),\n",
        "            validation_steps=100,\n",
        "            verbose=1,\n",
        "            callbacks=[checkpoint_callback]\n",
        "        )\n",
        "\n",
        "        # 모델 저장\n",
        "        model.save(os.path.join(self.model_output_dir, 'final_model.h5'))\n",
        "\n",
        "        # 학습 기록 저장\n",
        "        history_path = os.path.join(self.model_output_dir, 'history.pickle')\n",
        "        with open(history_path, 'wb') as f:\n",
        "            pickle.dump(history.history, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    classifier = FashionStyleClassifier()\n",
        "    classifier.train(num_classes)\n",
        "    print(\"Training finished!\")\n"
      ]
    }
  ]
}